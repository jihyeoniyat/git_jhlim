{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspce Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.46.0 (c:\\users\\limjh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages), Requirement.parse('azureml-core~=1.45.0')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.46.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "from azureml.core import (\n",
    "    Workspace,\n",
    "    Experiment,\n",
    "    Dataset,\n",
    "    Datastore,\n",
    "    ComputeTarget,\n",
    "    Environment,\n",
    "    ScriptRunConfig\n",
    ")\n",
    "\n",
    "from azureml.pipeline.core import (\n",
    "    Pipeline,\n",
    "    PipelineData,\n",
    "    PipelineEndpoint,\n",
    "    PublishedPipeline,\n",
    "    PipelineRun,\n",
    "    InputPortBinding\n",
    ")\n",
    "\n",
    "from azureml.pipeline.steps import (\n",
    "    PythonScriptStep,\n",
    "    DataTransferStep\n",
    ")\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "from azureml.data.datapath import (\n",
    "    DataPath, \n",
    "    DataPathComputeBinding, \n",
    "    DataReference\n",
    ")\n",
    "\n",
    "from azureml.data import (OutputFileDatasetConfig)\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlw-mlops-dev-002\n",
      "MLOps_POC\n",
      "7722d447-2b14-4ca2-83c1-b4df9454a55a\n"
     ]
    }
   ],
   "source": [
    "## 작업 영역 연결\n",
    "\n",
    "svc_pr= ServicePrincipalAuthentication(\n",
    "    tenant_id=\"247258cc-5eb2-4fd4-9bb2-f272103f0c34\",\n",
    "    service_principal_id=\"b7cfba68-a51b-4ae3-8885-cef273960a5e\",\n",
    "    service_principal_password=\"d4f8Q~~8tUXmQelSJyquy7lys17-t8gecKXCrb47\")\n",
    "\n",
    "\n",
    "ws = Workspace.get(subscription_id=\"7722d447-2b14-4ca2-83c1-b4df9454a55a\",\n",
    "                    resource_group=\"MLOps_POC\",\n",
    "                    name=\"mlw-mlops-dev-002\",\n",
    "                    auth=svc_pr)\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment / Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_pipeline\n",
      "Run configuration created :  Environment(Name: PV_env_test,\n",
      "Version: 1)\n"
     ]
    }
   ],
   "source": [
    "## Experiment\n",
    "experiment_folder = 'python_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok = True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cluster-mlops-jh\"\n",
    "\n",
    "# ## environment 생성 및 등록\n",
    "# experiment_env = Environment.from_conda_specification(\"PV_env_test\", experiment_folder + \"/conda.yml\")\n",
    "# experiment_env.register(workspace=ws)\n",
    "\n",
    "## environment 연결\n",
    "registered_env = Environment.get(ws, 'PV_env_test')\n",
    "pipeline_run_config = RunConfiguration()\n",
    "pipeline_run_config.target = cluster_name\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print(\"Run configuration created : \", registered_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datastore / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"busandatastore\",\n",
      "  \"container_name\": \"busan\",\n",
      "  \"account_name\": \"dlsmlopsdev002\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## 작업 영역에서 datasotre 가져오기 \n",
    "datastore = Datastore.get(ws, 'busandatastore')\n",
    "print(datastore)\n",
    "\n",
    "## input Dataset \n",
    "\n",
    "train_dataset = Dataset.get_by_name(ws,'tab_pvprediction_train')\n",
    "test_dataset = Dataset.get_by_name(ws,'tab_pvprediction_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline train steps defined\n",
      "Pipeline score steps defined\n",
      "Pipeline evaluate steps defined\n"
     ]
    }
   ],
   "source": [
    "## 각 스텝 output \n",
    "## PipelineData : 파이프라인의 중간 데이터\n",
    "\n",
    "model = PipelineData(\"model\",\n",
    "                     data_type = \"UriFolder\", \n",
    "                     output_mode='upload',\n",
    "                     output_path_on_compute = \"//datastores/busandatastore/paths/azureml/{name}/model/\")\n",
    "\n",
    "scored_data = PipelineData(\"scored_data\", \n",
    "                            data_type = \"UriFolder\", \n",
    "                            output_mode='upload',\n",
    "                            output_path_on_compute = \"//datastores/busandatastore/paths/azureml/{name}/scored_data/\")\n",
    "\n",
    "## train_step 파라미터값\n",
    "param_location = PipelineParameter(name=\"location\", default_value=\"busan\")\n",
    "param_test_size = PipelineParameter(name=\"test_size\", default_value=0.3)\n",
    "param_shuffle = PipelineParameter(name=\"shuffle\", default_value=True)\n",
    "param_random_state = PipelineParameter(name=\"random_state\", default_value=34)\n",
    "param_message = PipelineParameter(name=\"message\", default_value=\"AddParameterTest\")\n",
    "\n",
    "train_pipeline_param = PipelineParameter(name=\"traindata_param\", \n",
    "                                         default_value=train_dataset)\n",
    "traindata_input = DatasetConsumptionConfig(\"traindata\",train_pipeline_param)\n",
    "\n",
    "## score_step 파라미터값\n",
    "test_pipeline_param = PipelineParameter(name=\"testdata_param\", \n",
    "                                           default_value=test_dataset)\n",
    "\n",
    "## DatasetConsumptionConfig : 데이터 세트를 컴퓨팅 대상에 전달\n",
    "testdata_input = DatasetConsumptionConfig(\"testdata\",test_pipeline_param)\n",
    "\n",
    "## step 생성\n",
    "\n",
    "train_step = PythonScriptStep(\n",
    "    name=\"train step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"train_model.py\",\n",
    "    arguments=[ \"--model-path\", model,\n",
    "                \"--location\", param_location, \n",
    "                \"--test-size\", param_test_size, \n",
    "                \"--shuffle\" , param_shuffle, \n",
    "                \"--random-state\" , param_random_state, \n",
    "                \"--message\", param_message,\n",
    "                \"--param1\", traindata_input], \n",
    "    \n",
    "    inputs=[traindata_input],\n",
    "    outputs= [model],\n",
    "    \n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print(\"Pipeline train steps defined\")\n",
    "\n",
    "\n",
    "\n",
    "score_step = PythonScriptStep(\n",
    "    name=\"score step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"score_model.py\",\n",
    "    \n",
    "    arguments=[\"--model-path\", model,\n",
    "               \"--param1\", testdata_input,\n",
    "               \"--scoreddata-path\", scored_data],\n",
    "    \n",
    "    inputs=[testdata_input, model],\n",
    "    outputs=[scored_data],\n",
    "    \n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "print(\"Pipeline score steps defined\")\n",
    "\n",
    "\n",
    "\n",
    "evaluate_step = PythonScriptStep(\n",
    "    name=\"evaluate step\",\n",
    "    source_directory=experiment_folder,\n",
    "    script_name=\"evaluate_model.py\",\n",
    "    arguments=[\"--scoreddata-path\", scored_data],\n",
    "    inputs=[scored_data],\n",
    "    compute_target=cluster_name,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "print(\"Pipeline evaluate steps defined\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n",
      "Created step train step [bf16af1c][5b0d5866-e064-4214-9efd-ffdf899b3d6f], (This step will run and generate new outputs)\n",
      "Created step score step [c3e9761c][1df88655-41af-48eb-8cf2-2902a895d5b7], (This step will run and generate new outputs)\n",
      "Created step evaluate step [47a8ad24][2b110e55-695a-4c85-92a8-898e0e7ca114], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 9e8dc988-ced1-48f7-88c0-066a4782ef62\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9e8dc988-ced1-48f7-88c0-066a4782ef62?wsid=/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourcegroups/MLOps_POC/workspaces/mlw-mlops-dev-002&tid=247258cc-5eb2-4fd4-9bb2-f272103f0c34\n",
      "Pipeline submitted for execution.\n",
      "PipelineRunId: 9e8dc988-ced1-48f7-88c0-066a4782ef62\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9e8dc988-ced1-48f7-88c0-066a4782ef62?wsid=/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourcegroups/MLOps_POC/workspaces/mlw-mlops-dev-002&tid=247258cc-5eb2-4fd4-9bb2-f272103f0c34\n",
      "PipelineRun Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '9e8dc988-ced1-48f7-88c0-066a4782ef62', 'status': 'Completed', 'startTimeUtc': '2022-11-14T07:14:58.103411Z', 'endTimeUtc': '2022-11-14T07:39:00.718961Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"location\":\"busan\",\"test_size\":\"0.3\",\"shuffle\":\"True\",\"random_state\":\"34\",\"message\":\"AddParameterTest\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2022-11-14T07:14:58.3922708+00:00\",\"EndTime\":\"2022-11-14T07:39:00.6437859+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [{'dataset': {'id': '5e4fed79-a6a7-4081-a13e-90b34fa12dda'}, 'consumptionDetails': {'type': 'RunInput', 'mechanism': 'Direct'}}, {'dataset': {'id': '306225fd-23eb-4d44-a27d-ebd066eb343a'}, 'consumptionDetails': {'type': 'RunInput', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://stmlopsdev002.blob.core.windows.net/azureml/ExperimentRun/dcid.9e8dc988-ced1-48f7-88c0-066a4782ef62/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=k49%2FUdLpI9HLUZLB8UwQEn2IRScBvn9m%2BL7mfKoP%2BMQ%3D&skoid=d698a155-c061-4c34-ba2e-05f5677ae981&sktid=247258cc-5eb2-4fd4-9bb2-f272103f0c34&skt=2022-11-14T07%3A00%3A05Z&ske=2022-11-15T15%3A10%3A05Z&sks=b&skv=2019-07-07&st=2022-11-14T07%3A26%3A01Z&se=2022-11-14T15%3A36%3A01Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://stmlopsdev002.blob.core.windows.net/azureml/ExperimentRun/dcid.9e8dc988-ced1-48f7-88c0-066a4782ef62/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=IAx425LE3qnXrhELx5JGCANI37HUcvEJGeh6ft%2FOhVk%3D&skoid=d698a155-c061-4c34-ba2e-05f5677ae981&sktid=247258cc-5eb2-4fd4-9bb2-f272103f0c34&skt=2022-11-14T07%3A00%3A05Z&ske=2022-11-15T15%3A10%3A05Z&sks=b&skv=2019-07-07&st=2022-11-14T07%3A26%3A01Z&se=2022-11-14T15%3A36%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://stmlopsdev002.blob.core.windows.net/azureml/ExperimentRun/dcid.9e8dc988-ced1-48f7-88c0-066a4782ef62/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=%2FCa0E%2BZaDrocKRicgMfjReAr3yJv6JfCwlBYEQWU%2BcM%3D&skoid=d698a155-c061-4c34-ba2e-05f5677ae981&sktid=247258cc-5eb2-4fd4-9bb2-f272103f0c34&skt=2022-11-14T07%3A00%3A05Z&ske=2022-11-15T15%3A10%3A05Z&sks=b&skv=2019-07-07&st=2022-11-14T07%3A26%3A01Z&se=2022-11-14T15%3A36%3A01Z&sp=r'}, 'submittedBy': 'b7cfba68-a51b-4ae3-8885-cef273960a5e'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파이프라인 실행\n",
    "\n",
    "pipeline_steps = [train_step, score_step, evaluate_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "## Experiment 개체 생성\n",
    "exp = Experiment(workspace=ws,name=\"Pipeline_python_jh\")\n",
    "\n",
    "pipeline_run = exp.submit(pipeline,regenerate_outputs = True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'azureml.core.run' has no attribute 'register_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\limjh\\OneDrive\\바탕 화면\\git_jhlim\\2. 프로젝트\\2. MLOps\\src\\Pipeline_test.ipynb 셀 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m run \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m run\u001b[39m.\u001b[39;49mregister_model(model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbidaf_onnx\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                            tags\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39marea\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mqna\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                            model_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutputs/model.onnx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mname, model\u001b[39m.\u001b[39mid, model\u001b[39m.\u001b[39mversion, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'azureml.core.run' has no attribute 'register_model'"
     ]
    }
   ],
   "source": [
    "from azureml.core import run \n",
    "\n",
    "\n",
    "\n",
    "model = run.register_model(model_name='bidaf_onnx',\n",
    "                           tags={'area': 'qna'},\n",
    "                           model_path='outputs/model.onnx')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "deploy_config = {\"computeType\": \"aci\"}\n",
    "\n",
    "deployment_config_path = \"deployment_config.json\"\n",
    "# with open(deployment_config_path, \"w\") as outfile:\n",
    "#    outfile.write(json.dumps(deploy_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "No plugin found for managing model deployments to \"azureml\". In order to deploy models to \"azureml\", find and install an appropriate plugin from https://mlflow.org/docs/latest/plugins.html#community-plugins using your package manager (pip, conda etc).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\deployments\\plugin_manager.py:84\u001b[0m, in \u001b[0;36mDeploymentPlugins.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     83\u001b[0m     target_name \u001b[39m=\u001b[39m parse_target_uri(item)\n\u001b[1;32m---> 84\u001b[0m     plugin_like \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregistry[target_name]\n\u001b[0;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'azureml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\limjh\\OneDrive\\바탕 화면\\git_jhlim\\2. 프로젝트\\2. MLOps\\src\\Pipeline_test.ipynb 셀 12\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeployments\u001b[39;00m \u001b[39mimport\u001b[39;00m get_deploy_client\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Set the tracking uri in the deployment client.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m client \u001b[39m=\u001b[39m get_deploy_client(\u001b[39m\"\u001b[39;49m\u001b[39mazureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourceGroups/MLOps_POC/providers/Microsoft.MachineLearningServices/workspaces/mlw-mlops-dev-002\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\deployments\\interface.py:43\u001b[0m, in \u001b[0;36mget_deploy_client\u001b[1;34m(target_uri)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mReturns a subclass of :py:class:`mlflow.deployments.BaseDeploymentClient` exposing standard\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mAPIs for deploying models to the specified target. See available deployment APIs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m    client.delete_deployment(\"spamDetector\")\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m target \u001b[39m=\u001b[39m parse_target_uri(target_uri)\n\u001b[1;32m---> 43\u001b[0m plugin \u001b[39m=\u001b[39m plugin_store[target]\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m _, obj \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39mgetmembers(plugin):\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(obj):\n",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\deployments\\plugin_manager.py:93\u001b[0m, in \u001b[0;36mDeploymentPlugins.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m     87\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mNo plugin found for managing model deployments to \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{target}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to deploy models to \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{target}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, find and install an appropriate \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myour package manager (pip, conda etc).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m=\u001b[39mitem)\n\u001b[0;32m     92\u001b[0m     )\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(msg, error_code\u001b[39m=\u001b[39mRESOURCE_DOES_NOT_EXIST)\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(plugin_like, entrypoints\u001b[39m.\u001b[39mEntryPoint):\n\u001b[0;32m     96\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mMlflowException\u001b[0m: No plugin found for managing model deployments to \"azureml\". In order to deploy models to \"azureml\", find and install an appropriate plugin from https://mlflow.org/docs/latest/plugins.html#community-plugins using your package manager (pip, conda etc)."
     ]
    }
   ],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Set the tracking uri in the deployment client.\n",
    "client = get_deploy_client(\"azureml://koreacentral.api.azureml.ms/mlflow/v1.0/subscriptions/7722d447-2b14-4ca2-83c1-b4df9454a55a/resourceGroups/MLOps_POC/providers/Microsoft.MachineLearningServices/workspaces/mlw-mlops-dev-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mymodel_jh\"\n",
    "model_version = 1\n",
    "\n",
    "# define the model path and the name is the service name\n",
    "# if model is not registered, it gets registered automatically and a name is autogenerated using the \"name\" parameter below\n",
    "client.create_deployment(\n",
    "   model_uri=f\"models:/{model_name}/{model_version}\",\n",
    "   config={ \"deploy-config-file\": deployment_config_path },\n",
    "   name=\"mymodel-deployment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limjh\\AppData\\Local\\Temp\\ipykernel_25596\\3204224707.py:18: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration. \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(ws, service_name, [model], overwrite=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PipelineData' object has no attribute 'model_framework'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\limjh\\OneDrive\\바탕 화면\\git_jhlim\\2. 프로젝트\\2. MLOps\\src\\Pipeline_test.ipynb 셀 14\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazureml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebservice\u001b[39;00m \u001b[39mimport\u001b[39;00m AciWebservice\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m service_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdeploy-test\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m service \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39;49mdeploy(ws, service_name, [model], overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/limjh/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/git_jhlim/2.%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2.%20MLOps/src/Pipeline_test.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m service\u001b[39m.\u001b[39mwait_for_deployment(show_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azureml\\core\\model.py:1680\u001b[0m, in \u001b[0;36mModel.deploy\u001b[1;34m(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[39mif\u001b[39;00m deployment_config \u001b[39mand\u001b[39;00m deployment_config\u001b[39m.\u001b[39m_webservice_type\u001b[39m.\u001b[39m_webservice_type \u001b[39m==\u001b[39m IOT_WEBSERVICE_TYPE:\n\u001b[0;32m   1677\u001b[0m         \u001b[39mraise\u001b[39;00m WebserviceException(\u001b[39m'\u001b[39m\u001b[39mIoT Webservices must be deployed with an InferenceConfig.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1678\u001b[0m                                   logger\u001b[39m=\u001b[39mmodule_logger)\n\u001b[1;32m-> 1680\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49m_deploy_no_code(workspace, name, models, deployment_config, deployment_target,\n\u001b[0;32m   1681\u001b[0m                                  overwrite, show_output)\n\u001b[0;32m   1683\u001b[0m \u001b[39m# Environment-based webservice.\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deployment_config \u001b[39mor\u001b[39;00m deployment_config\u001b[39m.\u001b[39m_webservice_type\u001b[39m.\u001b[39m_webservice_type \u001b[39m!=\u001b[39m IOT_WEBSERVICE_TYPE:\n",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azureml\\core\\model.py:1864\u001b[0m, in \u001b[0;36mModel._deploy_no_code\u001b[1;34m(workspace, name, models, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m   1844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deploy_no_code\u001b[39m(workspace, name, models, deployment_config, deployment_target, overwrite, show_output):\n\u001b[0;32m   1845\u001b[0m     \u001b[39m\"\"\"Deploy the model without an explicit environment object or scoring code.\u001b[39;00m\n\u001b[0;32m   1846\u001b[0m \n\u001b[0;32m   1847\u001b[0m \u001b[39m    :param workspace:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[39m    :rtype: azureml.core.Webservice\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1864\u001b[0m     environment_image_request \u001b[39m=\u001b[39m build_and_validate_no_code_environment_image_request(models)\n\u001b[0;32m   1866\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39m_deploy_with_environment_image_request(workspace, name, environment_image_request,\n\u001b[0;32m   1867\u001b[0m                                                         deployment_config, deployment_target, overwrite,\n\u001b[0;32m   1868\u001b[0m                                                         show_output)\n",
      "File \u001b[1;32mc:\\Users\\limjh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azureml\\_model_management\\_util.py:1184\u001b[0m, in \u001b[0;36mbuild_and_validate_no_code_environment_image_request\u001b[1;34m(models)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     \u001b[39mraise\u001b[39;00m UserErrorException(\u001b[39m'\u001b[39m\u001b[39mYou must provide an InferenceConfig when deploying zero or multiple models.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1182\u001b[0m model \u001b[39m=\u001b[39m models[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1184\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39;49mmodel_framework \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m Model\u001b[39m.\u001b[39m_SUPPORTED_FRAMEWORKS_FOR_NO_CODE_DEPLOY:\n\u001b[0;32m   1185\u001b[0m     \u001b[39mraise\u001b[39;00m UserErrorException(\u001b[39m'\u001b[39m\u001b[39mYou must provide an InferenceConfig when deploying a model with model_framework \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1186\u001b[0m                              \u001b[39m'\u001b[39m\u001b[39mset to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Default environments are only provided for these frameworks: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1187\u001b[0m                              \u001b[39m.\u001b[39mformat(model\u001b[39m.\u001b[39mmodel_framework, Model\u001b[39m.\u001b[39m_SUPPORTED_FRAMEWORKS_FOR_NO_CODE_DEPLOY))\n\u001b[0;32m   1189\u001b[0m \u001b[39m# Only specify the model IDs; MMS will provide the environment, driver program, etc.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelineData' object has no attribute 'model_framework'"
     ]
    }
   ],
   "source": [
    "# from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "# from azureml.core.model import InferenceConfig\n",
    "\n",
    "# inference_config = InferenceConfig(entry_script='score.py', environment=registered_env)\n",
    "\n",
    "# deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "# service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\n",
    "# service.wait_for_deployment(show_output = True)\n",
    "# print(service.state)\n",
    "\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "service_name = 'deploy-test'\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "\n",
    "\n",
    "# service_name = 'my-custom-env-service'\n",
    "\n",
    "# inference_config = InferenceConfig(entry_script='python_pipeline/score_model.py', environment=registered_env)\n",
    "# aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# service = Model.deploy(workspace=ws,\n",
    "#                           name=service_name,\n",
    "#                           models=[model],\n",
    "#                           inference_config=inference_config,\n",
    "#                           deployment_config=aci_config,\n",
    "#                           overwrite=True)\n",
    "# service.wait_for_deployment(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3335486d84fce0a15d9b8359c7f75eef8841ddabe681c849f2c41d9c2eb61c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
